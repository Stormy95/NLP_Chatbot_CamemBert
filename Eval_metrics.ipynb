{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Développement-de-notre-propre-technique-d'évaluation-d'une-réponse\" data-toc-modified-id=\"Développement-de-notre-propre-technique-d'évaluation-d'une-réponse-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Développement de notre propre technique d'évaluation d'une réponse</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quelques-exemples-de-réponses...\" data-toc-modified-id=\"Quelques-exemples-de-réponses...-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Quelques exemples de réponses...</a></span></li><li><span><a href=\"#Cleaning\" data-toc-modified-id=\"Cleaning-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cleaning</a></span></li><li><span><a href=\"#Vectorisation\" data-toc-modified-id=\"Vectorisation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Vectorisation</a></span></li><li><span><a href=\"#Cosine-similarity\" data-toc-modified-id=\"Cosine-similarity-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Cosine similarity</a></span></li><li><span><a href=\"#Distance-2-à-2\" data-toc-modified-id=\"Distance-2-à-2-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Distance 2 à 2</a></span></li><li><span><a href=\"#Wrapping-up\" data-toc-modified-id=\"Wrapping-up-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Wrapping up</a></span></li></ul></li><li><span><a href=\"#Utilisation-de-package-haystack-pour-évaluer-les-questions/réponses-d'un-modèle\" data-toc-modified-id=\"Utilisation-de-package-haystack-pour-évaluer-les-questions/réponses-d'un-modèle-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Utilisation de package haystack pour évaluer les questions/réponses d'un modèle</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importer-les-données-de-test\" data-toc-modified-id=\"Importer-les-données-de-test-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Importer les données de test</a></span></li><li><span><a href=\"#Importer-un-modèle-et-évaluer-sur-toutes-les-questions/réponses-de-test.\" data-toc-modified-id=\"Importer-un-modèle-et-évaluer-sur-toutes-les-questions/réponses-de-test.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Importer un modèle et évaluer sur toutes les questions/réponses de test.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Développement de notre propre technique d'évaluation d'une réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1647700993624,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "b-UuNP4QfFd_",
    "outputId": "ba1d473e-e72b-4375-fd56-1f0f8ce5cca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxVxkHjdedJ0"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W4_k3SifK4K"
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQP_FNxq1bq8"
   },
   "source": [
    "## Quelques exemples de réponses...\n",
    "\n",
    "La premier élément de la liste est la réponse \"vraie\" i.e. celle attendue et renseigné dans les fichiers `json`. Les autres éléments de la liste servent d'exemple de réponse qui pourraient être renvoyées par le Chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiJ8b90KfPac"
   },
   "outputs": [],
   "source": [
    "response = [\n",
    "            \"remplacer l’hydrogène fossile (issu à 95% du gaz, pétrole et charbon) actuellement utilisé par l’industrie dans ses process en France (dans le secteur du raffinage, de la production d’ammoniac ou de la chimie) par de l’hydrogène bas-carbone\",\n",
    "            \"remplacer les hydrocarbures\",\n",
    "            \"hydrogène bas-carbone\",\n",
    "            \"ne pas utiliser d'hydrogène bas-carbone\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqVh5lER10XX"
   },
   "source": [
    "## Cleaning\n",
    "Retrait de la ponctuation et des mots de fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgHIkhvTf5vj"
   },
   "outputs": [],
   "source": [
    "def clean_string(text: str):\n",
    "    text = ''.join([w for w in text if w not in string.punctuation])\n",
    "    text = text.lower()\n",
    "    text = ' '.join([w for w in text.split() if w not in stopwords])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647701005233,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "M4SHmUlmgT42",
    "outputId": "8a151978-c7ca-490c-9a28-e2b9a3d09d2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remplacer l’hydrogène fossile issu 95 gaz pétrole charbon actuellement utilisé l’industrie process france secteur raffinage production d’ammoniac chimie l’hydrogène bascarbone',\n",
       " 'remplacer hydrocarbures',\n",
       " 'hydrogène bascarbone',\n",
       " 'utiliser dhydrogène bascarbone']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_clean = list(map(clean_string, response))\n",
    "response_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lJIYDCw1_KU"
   },
   "source": [
    "## Vectorisation\n",
    "Vectorisation et création de la matrice des tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1647701008124,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "ei4urtnsghS7",
    "outputId": "ebb41feb-55d0-40ad-ba3e-e25c8380d4fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['95', 'actuellement', 'ammoniac', 'bascarbone', 'charbon',\n",
       "       'chimie', 'dhydrogène', 'fossile', 'france', 'gaz',\n",
       "       'hydrocarbures', 'hydrogène', 'industrie', 'issu', 'process',\n",
       "       'production', 'pétrole', 'raffinage', 'remplacer', 'secteur',\n",
       "       'utiliser', 'utilisé'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vect = vectorizer.fit_transform(response_clean).toarray()\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1647701010309,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "as6DZSQPhh2d",
    "outputId": "c7c4a027-3d77-47f4-910c-d8ccf3323756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R75o2J6w2J4G"
   },
   "source": [
    "## Cosine similarity\n",
    "Calcul de la matrice des distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1647701012108,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "YMB-cWiSgxq_",
    "outputId": "003d2f71-5a68-4dd3-d709-581b9ae508ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.15075567, 0.45226702, 0.12309149],\n",
       "       [0.15075567, 1.        , 0.        , 0.        ],\n",
       "       [0.45226702, 0.        , 1.        , 0.40824829],\n",
       "       [0.12309149, 0.        , 0.40824829, 1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fE4biTM2W2T"
   },
   "source": [
    "## Distance 2 à 2\n",
    "Reprises des calculs de distances: renvoyer une distance pour uniquement deux réponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzBNR6IYhOG5"
   },
   "outputs": [],
   "source": [
    "def simi_cosim(va, vb):\n",
    "    va = va.reshape(1, -1)\n",
    "    vb = vb.reshape(1, -1)\n",
    "\n",
    "    return cosine_similarity(va, vb)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647701015818,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "Z8xTZ3rLzvlg",
    "outputId": "9cea72ee-2a9e-4be0-d193-df7d12ec5335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4522670168666454"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi_cosim(vect[0], vect[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFbUGHNMoOPP"
   },
   "source": [
    "## Wrapping up  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1647701017214,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "Ak8Y2Y6CrAOv",
    "outputId": "afca6173-d964-40e7-ca2f-6ed53da9929d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVpxhRzboOrI"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('french')\n",
    "\n",
    "def eval_similirity(out_resp: str, exp_resp: str):\n",
    "    \"\"\" Computes cosine similarity between 2 answers\n",
    "\n",
    "    Args:\n",
    "      out_resp (str): the response to be evaluated\n",
    "      exp_resp (str): the response expexted\n",
    "\n",
    "    Returns:\n",
    "      similarity (float): the cosine similirity computed between out_resp and\n",
    "      exp_resp\n",
    "    \"\"\"\n",
    "\n",
    "    out_resp = ''.join([w for w in out_resp if w not in string.punctuation])\n",
    "    exp_resp = ''.join([w for w in exp_resp if w not in string.punctuation])\n",
    "\n",
    "    out_resp = out_resp.lower()\n",
    "    exp_resp = exp_resp.lower()\n",
    "\n",
    "    out_resp = ' '.join([w for w in out_resp.split() if w not in stopwords])\n",
    "    exp_resp = ' '.join([w for w in exp_resp.split() if w not in stopwords])\n",
    "\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    vect = vectorizer.fit_transform([exp_resp, out_resp]).toarray()\n",
    "\n",
    "    return cosine_similarity(vect[0].reshape(1, -1), vect[1].reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1647701022767,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "-3kbMH04q7Jv",
    "outputId": "1861a0f0-010a-4533-ae54-870a88ea95e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26726124191242434"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_similirity(\"this is the first document we found\", \"third document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de package haystack pour évaluer les questions/réponses d'un modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbqZlPB6oSVw"
   },
   "source": [
    "## Importer les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1648116604705,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "uVRLemStoUa5"
   },
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# Opening JSON file\n",
    "f = open(\"/content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/Question-Réponse/data_test_squad_format.json\")\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data_test = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1647952778247,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "1E4QKp37pcKH",
    "outputId": "8385f763-4570-4cc3-ed25-25ee989a65b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'context': 'Si les défis technologiques et de R&D associés apparaissent «dépassables» dans les décennies à venir, les scénarios «100% renouvelable» ou fondés sur la prolongation à long terme des réacteurs nucléaires actuels au-delà de 60 ans impliquent qu’un grand nombre de prérequis techniques critiques soient respectés à court terme. Or rien ne le garantit en l’état. Décider de ces scénarios aujourd’hui, ou renoncer au principe de diversification technologique dans le mix de production électrique, soulève donc un risque de non-atteinte de l’objectif de neutralité carbone à la date rapprochée de 2050.',\n",
       "   'document_id': 15,\n",
       "   'qas': [{'answers': [{'answer_category': 'SHORT',\n",
       "       'answer_id': 5015,\n",
       "       'answer_start': 247,\n",
       "       'document_id': 15,\n",
       "       'question_id': 1015,\n",
       "       'text': 'grand nombre de prérequis techniques critiques soient respectés à court terme'}],\n",
       "     'id': 1015,\n",
       "     'is_impossible': False,\n",
       "     'question': 'Que sous-entendent les scénarios 100% renouvelables ou de prolongation des centrales nucléaires au delà de 60 ans ?'}]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1647952791828,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "Kl4ai8fco9pF",
    "outputId": "67c7a5ab-5348-499b-d50f-325b494df4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14814,
     "status": "ok",
     "timestamp": 1648116603830,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "Mrb9cZv_o7Jk",
    "outputId": "2dda4901-7e3a-449d-c656-92e597d5efe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndNg505toJt_"
   },
   "source": [
    "## Importer un modèle et évaluer sur toutes les questions/réponses de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ox-n4pjXrzuf"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49307,
     "status": "ok",
     "timestamp": 1648117064710,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "H0qZuYUqn9wz",
    "outputId": "047c827c-0832-46c0-be5d-a2fd78d11d1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at /content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/camembertV2\n",
      "INFO - haystack.modeling.model.language_model -  Loaded /content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/camembertV2\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": true, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from /content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/camembertV2/prediction_head_0.bin\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 2 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0     0  \n",
      "INFO - haystack.modeling.infer -  /w\\   /w\\ \n",
      "INFO - haystack.modeling.infer -  /'\\   / \\ \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from haystack.utils import convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import FARMReader, TransformersReader\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import ElasticsearchRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# #############################################\n",
    "# ## Launching and setting up pipe obj       ##\n",
    "# #############################################\n",
    "from haystack.utils import launch_es\n",
    "\n",
    "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "! chown -R daemon:daemon elasticsearch-7.9.2\n",
    "\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "es_server = Popen(\n",
    "    [\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1)  # as daemon\n",
    ")\n",
    "# wait until ES has started\n",
    "! sleep 30\n",
    "\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
    "report_path = \"/content/drive/MyDrive/Projet Option - ChatBot/0 - Biblio/rapport_rte_v2.json\"\n",
    "\n",
    "# Import text \n",
    "with open(report_path) as json_file:\n",
    "    dict_rapport = json.load(json_file)[\"data\"]\n",
    "\n",
    "# write document on ElasticSearch server\n",
    "document_store.write_documents(dict_rapport)\n",
    "\n",
    "## Initalize Retriever, Reader,  & Pipeline\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)\n",
    "reader = FARMReader(model_name_or_path=\"/content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/camembertV2\", use_gpu=True)\n",
    "# reader = FARMReader(model_name_or_path=\"saattrupdan/xlmr-base-texas-squad-fr\", use_gpu=True)\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymOgWM0UpnUw"
   },
   "source": [
    "Evaluer sur chaque question/réponse (on évalue sur la capacité à trouver la réponse la plus proche sur les 3 réponses):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1648116797178,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "l6G4K53R0ypH",
    "outputId": "e659fe8e-24d7-4ccb-e0f2-4fa5fb3617a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.384185791015625e-07"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "time.time()-time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27085,
     "status": "ok",
     "timestamp": 1648117105574,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "dsU9TkyZr1Td",
    "outputId": "bebd822b-ba17-4c64-b35c-7d1254a16647"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]/usr/local/lib/python3.7/dist-packages/haystack/modeling/model/prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.23 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.76 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.87 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.00 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.82 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.83 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.96 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.61 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.77 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.96 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.36 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.94 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.93 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.89 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.41 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.26 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.50 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.71 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.84 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.09 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.22 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.46 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.18 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.08 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.71 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.57 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.38 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.17 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.47 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.21 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.47 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.54 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.52 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.97 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.19 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.55 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.73 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.61 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.26 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.21 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.81 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.55 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.77 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.70 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.79 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.63 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.98 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.79 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.55 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.12 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.83 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.47 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.51 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.46 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.11 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.61 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.79 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.52 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.07 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.74 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.24 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.82 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.33 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.61 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.69 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.23 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.22 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.25 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.58 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.93 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.00 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.10 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.42 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.92 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.70 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.82 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.32 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.98 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.15 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.87 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.60 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.54 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.31 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.57 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 11.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.09 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.96 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.71 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.90 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.28 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.51 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.18 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 16.52 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.89 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.98 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.08 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 15.23 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.50 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.78 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.11 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.36 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 29.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.91 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.42 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.31 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.27 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 25.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.71 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.90 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.90 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 27.33 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 13.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 17.96 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.92 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.35 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.73 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.38 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.66 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.45 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.33 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 24.26 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 26.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.10 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.60 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.36 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.46 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 33.36 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.48 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 23.59 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.83 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.81 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.41 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 20.91 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 22.55 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 28.70 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 30.72 Batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 evaluations finished in : 26s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We can load evaluation labels from the document store\n",
    "# We are also opting to filter out no_answer samples\n",
    "# eval_labels = document_store.get_all_labels_aggregated(drop_negative_labels=True, drop_no_answers=False)\n",
    "# eval_labels = [label for label in eval_labels if not label.no_answer]  # filter out no_answer cases\n",
    "\n",
    "## Alternative: Define queries and labels directly\n",
    "from haystack.schema import EvaluationResult, MultiLabel, Label, Answer, Document\n",
    "start = time.time()\n",
    "eval_labels = [\n",
    "   MultiLabel(\n",
    "       labels=[\n",
    "           Label(\n",
    "               query=data_test[\"data\"][i][\"paragraphs\"][0]['qas'][0]['question'],\n",
    "               answer=Answer(\n",
    "                   answer=data_test[\"data\"][i][\"paragraphs\"][0]['qas'][0]['answers'][0]['text'],\n",
    "               ),\n",
    "               document=Document(\n",
    "                   id=data_test[\"data\"][i][\"paragraphs\"][0]['document_id'],\n",
    "                   content_type=\"text\",\n",
    "                   content=data_test[\"data\"][i][\"paragraphs\"][0]['context']\n",
    "               ),\n",
    "               is_correct_answer=True,\n",
    "               is_correct_document=True,\n",
    "               origin=\"gold-label\"\n",
    "           )\n",
    "       ]\n",
    "   ) for i in range(len(data_test[\"data\"]))\n",
    "]\n",
    "\n",
    "docs = [[Document(\n",
    "                   id=data_test[\"data\"][i][\"paragraphs\"][0]['document_id'],\n",
    "                   content_type=\"text\",\n",
    "                   content=data_test[\"data\"][i][\"paragraphs\"][0]['context']\n",
    "               ) for i in range(len(data_test[\"data\"])) ]]\n",
    "\n",
    "\n",
    "# Similar to pipeline.run() we can execute pipeline.eval()\n",
    "eval_result = pipe.eval(labels=eval_labels, params={\"Retriever\": {\"top_k\": 3}})\n",
    "print(f\"60 evaluations finished in : {int(time.time()-start)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1647876702800,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "rZqaA6US8auc",
    "outputId": "7fca00d2-6d12-41eb-bae6-39de0970f2b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43333333333333335"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1647882192277,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "8bozSBLt2h0D",
    "outputId": "d2d3b09c-0bcb-420a-c937-4085fa251158"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b271af24-bca4-4481-92cb-2176faa8850c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multilabel_id</th>\n",
       "      <th>query</th>\n",
       "      <th>filters</th>\n",
       "      <th>gold_answers</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>rank</th>\n",
       "      <th>document_id</th>\n",
       "      <th>gold_document_ids</th>\n",
       "      <th>offsets_in_document</th>\n",
       "      <th>gold_offsets_in_documents</th>\n",
       "      <th>type</th>\n",
       "      <th>node</th>\n",
       "      <th>eval_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-677990051653884372</td>\n",
       "      <td>Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[grand nombre de prérequis techniques critiques soient respectés à court terme]</td>\n",
       "      <td>un grand nombre de prérequis techniques critiques soient respectés à court t...</td>\n",
       "      <td>ls au-delà de 60 ans impliquent qu’un grand nombre de prérequis techniques c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312295387148fc8fa6015cdae4e1c14</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[{'start': 244, 'end': 324}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>answer</td>\n",
       "      <td>Reader</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-677990051653884372</td>\n",
       "      <td>Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[grand nombre de prérequis techniques critiques soient respectés à court terme]</td>\n",
       "      <td>«volume exceptionnel de travaux».</td>\n",
       "      <td>qué que la prolongation au-delà de 40 ans, pour laquelle elle a rendu un avi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8dd9975d24d0b368950611dbe67cf30a</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[{'start': 378, 'end': 411}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>answer</td>\n",
       "      <td>Reader</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-677990051653884372</td>\n",
       "      <td>Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[grand nombre de prérequis techniques critiques soient respectés à court terme]</td>\n",
       "      <td>renouvelables, ou celui nécessitant la prolongation</td>\n",
       "      <td>Les scénarios à très hautes parts d’énergies renouvelables, ou celui nécessi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b4431cd74a2b7f1e2ffe3d3c9638f213</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[{'start': 45, 'end': 96}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>answer</td>\n",
       "      <td>Reader</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5483248663165921264</td>\n",
       "      <td>De quoi s'affranchissent les scénarios type N2 ?</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[plusieurs paris techniques et industriels]</td>\n",
       "      <td>techniques et industriels</td>\n",
       "      <td>arios de type N2 permettent de s’affranchir de plusieurs paris techniques et...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e9165f570093198da913fea53deb2254</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[{'start': 71, 'end': 96}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>answer</td>\n",
       "      <td>Reader</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5483248663165921264</td>\n",
       "      <td>De quoi s'affranchissent les scénarios type N2 ?</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[plusieurs paris techniques et industriels]</td>\n",
       "      <td>volontarisme pour l’installation des énergies renouvelables</td>\n",
       "      <td>s pleinement concrétisées dans les faits : les scénarios N2 et N03 supposent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>d565b75cbe9ebdf19f3c3eb4799c4863</td>\n",
       "      <td>[24]</td>\n",
       "      <td>[{'start': 508, 'end': 567}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>answer</td>\n",
       "      <td>Reader</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b271af24-bca4-4481-92cb-2176faa8850c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b271af24-bca4-4481-92cb-2176faa8850c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b271af24-bca4-4481-92cb-2176faa8850c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         multilabel_id  \\\n",
       "0  -677990051653884372   \n",
       "1  -677990051653884372   \n",
       "2  -677990051653884372   \n",
       "0 -5483248663165921264   \n",
       "1 -5483248663165921264   \n",
       "\n",
       "                                                                             query  \\\n",
       "0  Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...   \n",
       "1  Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...   \n",
       "2  Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...   \n",
       "0                                 De quoi s'affranchissent les scénarios type N2 ?   \n",
       "1                                 De quoi s'affranchissent les scénarios type N2 ?   \n",
       "\n",
       "   filters  \\\n",
       "0  b'null'   \n",
       "1  b'null'   \n",
       "2  b'null'   \n",
       "0  b'null'   \n",
       "1  b'null'   \n",
       "\n",
       "                                                                      gold_answers  \\\n",
       "0  [grand nombre de prérequis techniques critiques soient respectés à court terme]   \n",
       "1  [grand nombre de prérequis techniques critiques soient respectés à court terme]   \n",
       "2  [grand nombre de prérequis techniques critiques soient respectés à court terme]   \n",
       "0                                      [plusieurs paris techniques et industriels]   \n",
       "1                                      [plusieurs paris techniques et industriels]   \n",
       "\n",
       "                                                                            answer  \\\n",
       "0  un grand nombre de prérequis techniques critiques soient respectés à court t...   \n",
       "1                                                «volume exceptionnel de travaux».   \n",
       "2                              renouvelables, ou celui nécessitant la prolongation   \n",
       "0                                                        techniques et industriels   \n",
       "1                      volontarisme pour l’installation des énergies renouvelables   \n",
       "\n",
       "                                                                           context  \\\n",
       "0  ls au-delà de 60 ans impliquent qu’un grand nombre de prérequis techniques c...   \n",
       "1  qué que la prolongation au-delà de 40 ans, pour laquelle elle a rendu un avi...   \n",
       "2  Les scénarios à très hautes parts d’énergies renouvelables, ou celui nécessi...   \n",
       "0  arios de type N2 permettent de s’affranchir de plusieurs paris techniques et...   \n",
       "1  s pleinement concrétisées dans les faits : les scénarios N2 et N03 supposent...   \n",
       "\n",
       "   exact_match        f1  rank                       document_id  \\\n",
       "0          0.0  0.956522   1.0   312295387148fc8fa6015cdae4e1c14   \n",
       "1          0.0  0.133333   2.0  8dd9975d24d0b368950611dbe67cf30a   \n",
       "2          0.0  0.000000   3.0  b4431cd74a2b7f1e2ffe3d3c9638f213   \n",
       "0          0.0  0.750000   1.0  e9165f570093198da913fea53deb2254   \n",
       "1          0.0  0.000000   2.0  d565b75cbe9ebdf19f3c3eb4799c4863   \n",
       "\n",
       "  gold_document_ids           offsets_in_document gold_offsets_in_documents  \\\n",
       "0              [15]  [{'start': 244, 'end': 324}]                        []   \n",
       "1              [15]  [{'start': 378, 'end': 411}]                        []   \n",
       "2              [15]    [{'start': 45, 'end': 96}]                        []   \n",
       "0              [24]    [{'start': 71, 'end': 96}]                        []   \n",
       "1              [24]  [{'start': 508, 'end': 567}]                        []   \n",
       "\n",
       "     type    node   eval_mode  \n",
       "0  answer  Reader  integrated  \n",
       "1  answer  Reader  integrated  \n",
       "2  answer  Reader  integrated  \n",
       "0  answer  Reader  integrated  \n",
       "1  answer  Reader  integrated  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_result = eval_result[\"Reader\"]\n",
    "reader_result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxdCz6xa3Dgg"
   },
   "outputs": [],
   "source": [
    "# reader_result.to_csv(\"/content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/eval_CamembertV2.csv\")\n",
    "#reader_result.to_csv(\"/content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/eval_Camembert.csv\")\n",
    "reader_result.to_csv(\"/content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/eval_xlm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "error",
     "timestamp": 1648117105575,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "1VIftoDC8okl",
    "outputId": "57796d0a-8097-41a5-d268-93ee68e287fb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8ade9f1bca45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreader_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reader_result' is not defined"
     ]
    }
   ],
   "source": [
    "reader_result[\"f1\"].iloc[3*2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1648117108166,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "n0jRXRdsbx1t",
    "outputId": "3568e2de-3ff3-4e11-98a5-16effd6b00df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b9906c16-6e69-4e4a-bdb1-17865a2c137e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multilabel_id</th>\n",
       "      <th>query</th>\n",
       "      <th>filters</th>\n",
       "      <th>gold_document_contents</th>\n",
       "      <th>content</th>\n",
       "      <th>gold_id_match</th>\n",
       "      <th>answer_match</th>\n",
       "      <th>gold_id_or_answer_match</th>\n",
       "      <th>rank</th>\n",
       "      <th>document_id</th>\n",
       "      <th>gold_document_ids</th>\n",
       "      <th>type</th>\n",
       "      <th>node</th>\n",
       "      <th>eval_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4574023199644543112</td>\n",
       "      <td>Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[Si les défis technologiques et de R&amp;D associés apparaissent «dépassables» d...</td>\n",
       "      <td>Les scénarios à très hautes parts d’énergies renouvelables, ou celui nécessi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b4431cd74a2b7f1e2ffe3d3c9638f213</td>\n",
       "      <td>[15]</td>\n",
       "      <td>document</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4574023199644543112</td>\n",
       "      <td>Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[Si les défis technologiques et de R&amp;D associés apparaissent «dépassables» d...</td>\n",
       "      <td>Si les défis technologiques et de R&amp;D associés apparaissent «dépassables» da...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>312295387148fc8fa6015cdae4e1c14</td>\n",
       "      <td>[15]</td>\n",
       "      <td>document</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4574023199644543112</td>\n",
       "      <td>Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[Si les défis technologiques et de R&amp;D associés apparaissent «dépassables» d...</td>\n",
       "      <td>Cinq des six scénarios des «Futurs énergétiques 2050» reposent sur une explo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8dd9975d24d0b368950611dbe67cf30a</td>\n",
       "      <td>[15]</td>\n",
       "      <td>document</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7532756540141021476</td>\n",
       "      <td>De quoi s'affranchissent les scénarios type N2 ?</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[Les scénarios de type N2 permettent de s’affranchir de plusieurs paris tech...</td>\n",
       "      <td>Les scénarios de type N2 permettent de s’affranchir de plusieurs paris techn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e9165f570093198da913fea53deb2254</td>\n",
       "      <td>[24]</td>\n",
       "      <td>document</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7532756540141021476</td>\n",
       "      <td>De quoi s'affranchissent les scénarios type N2 ?</td>\n",
       "      <td>b'null'</td>\n",
       "      <td>[Les scénarios de type N2 permettent de s’affranchir de plusieurs paris tech...</td>\n",
       "      <td>Les scénarios N2 et N03, qui reposent sur le maintien durable d’un parc nucl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>d565b75cbe9ebdf19f3c3eb4799c4863</td>\n",
       "      <td>[24]</td>\n",
       "      <td>document</td>\n",
       "      <td>Retriever</td>\n",
       "      <td>integrated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9906c16-6e69-4e4a-bdb1-17865a2c137e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b9906c16-6e69-4e4a-bdb1-17865a2c137e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b9906c16-6e69-4e4a-bdb1-17865a2c137e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         multilabel_id  \\\n",
       "0 -4574023199644543112   \n",
       "1 -4574023199644543112   \n",
       "2 -4574023199644543112   \n",
       "0 -7532756540141021476   \n",
       "1 -7532756540141021476   \n",
       "\n",
       "                                                                             query  \\\n",
       "0  Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...   \n",
       "1  Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...   \n",
       "2  Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...   \n",
       "0                                 De quoi s'affranchissent les scénarios type N2 ?   \n",
       "1                                 De quoi s'affranchissent les scénarios type N2 ?   \n",
       "\n",
       "   filters  \\\n",
       "0  b'null'   \n",
       "1  b'null'   \n",
       "2  b'null'   \n",
       "0  b'null'   \n",
       "1  b'null'   \n",
       "\n",
       "                                                            gold_document_contents  \\\n",
       "0  [Si les défis technologiques et de R&D associés apparaissent «dépassables» d...   \n",
       "1  [Si les défis technologiques et de R&D associés apparaissent «dépassables» d...   \n",
       "2  [Si les défis technologiques et de R&D associés apparaissent «dépassables» d...   \n",
       "0  [Les scénarios de type N2 permettent de s’affranchir de plusieurs paris tech...   \n",
       "1  [Les scénarios de type N2 permettent de s’affranchir de plusieurs paris tech...   \n",
       "\n",
       "                                                                           content  \\\n",
       "0  Les scénarios à très hautes parts d’énergies renouvelables, ou celui nécessi...   \n",
       "1  Si les défis technologiques et de R&D associés apparaissent «dépassables» da...   \n",
       "2  Cinq des six scénarios des «Futurs énergétiques 2050» reposent sur une explo...   \n",
       "0  Les scénarios de type N2 permettent de s’affranchir de plusieurs paris techn...   \n",
       "1  Les scénarios N2 et N03, qui reposent sur le maintien durable d’un parc nucl...   \n",
       "\n",
       "   gold_id_match  answer_match  gold_id_or_answer_match  rank  \\\n",
       "0            0.0           0.0                      0.0   1.0   \n",
       "1            0.0           1.0                      1.0   2.0   \n",
       "2            0.0           0.0                      0.0   3.0   \n",
       "0            0.0           1.0                      1.0   1.0   \n",
       "1            0.0           0.0                      0.0   2.0   \n",
       "\n",
       "                        document_id gold_document_ids      type       node  \\\n",
       "0  b4431cd74a2b7f1e2ffe3d3c9638f213              [15]  document  Retriever   \n",
       "1   312295387148fc8fa6015cdae4e1c14              [15]  document  Retriever   \n",
       "2  8dd9975d24d0b368950611dbe67cf30a              [15]  document  Retriever   \n",
       "0  e9165f570093198da913fea53deb2254              [24]  document  Retriever   \n",
       "1  d565b75cbe9ebdf19f3c3eb4799c4863              [24]  document  Retriever   \n",
       "\n",
       "    eval_mode  \n",
       "0  integrated  \n",
       "1  integrated  \n",
       "2  integrated  \n",
       "0  integrated  \n",
       "1  integrated  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_result = eval_result[\"Retriever\"]\n",
    "retriever_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1648117325550,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "rfVE63rQcMBZ",
    "outputId": "1820f4eb-ee22-47a9-e6aa-266c09e872c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36666666666666664"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_result[retriever_result[\"rank\"]==1.0][\"gold_id_or_answer_match\"].sum()/len(retriever_result[retriever_result[\"rank\"]==1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648117167964,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "-dzb2isBcB2_",
    "outputId": "40d26705-5bd8-474c-8dc2-98f5c45bf021"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multilabel_id                                                                         -4574023199644543112\n",
       "query                      Que sous-entendent les scénarios 100% renouvelables ou de prolongation des c...\n",
       "filters                                                                                            b'null'\n",
       "gold_document_contents     [Si les défis technologiques et de R&D associés apparaissent «dépassables» d...\n",
       "content                    Les scénarios à très hautes parts d’énergies renouvelables, ou celui nécessi...\n",
       "gold_id_match                                                                                          0.0\n",
       "answer_match                                                                                           0.0\n",
       "gold_id_or_answer_match                                                                                0.0\n",
       "rank                                                                                                   1.0\n",
       "document_id                                                               b4431cd74a2b7f1e2ffe3d3c9638f213\n",
       "gold_document_ids                                                                                     [15]\n",
       "type                                                                                              document\n",
       "node                                                                                             Retriever\n",
       "eval_mode                                                                                       integrated\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_result.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1647882201675,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "hMWIqja98Acw",
    "outputId": "1dad3cc6-e5ab-413b-bce1-0b84af1ab623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37849922625677107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_f1 = []\n",
    "for i in range(len(reader_result)//3):\n",
    "  f1 = max(reader_result[\"f1\"].iloc[3*i], reader_result[\"f1\"].iloc[3*i+1], reader_result[\"f1\"].iloc[3*i+2])\n",
    "  all_f1.append(f1)\n",
    "np.mean(all_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1647878948515,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "wcduq6KpHsen",
    "outputId": "ccb03f85-1f02-4f97-9650-bcc6d19c0322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La moyenne du f1 score de la première réponse est 0.24524329826585775\n",
      "La moyenne du f1 score de la deuxième réponse est 0.15367713689846546\n",
      "La moyenne du f1 score de la deuxième réponse est 0.04712201303167415\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f1_first = []\n",
    "f1_second = []\n",
    "f1_third = []\n",
    "\n",
    "for i in range(len(reader_result)//3):\n",
    "    f1_first.append(reader_result[\"f1\"].iloc[3*i])\n",
    "    f1_second.append(reader_result[\"f1\"].iloc[3*i+1])\n",
    "    f1_third.append(reader_result[\"f1\"].iloc[3*i+2])\n",
    "print(f\"La moyenne du f1 score de la première réponse est {np.mean(f1_first)}\")\n",
    "print(f\"La moyenne du f1 score de la deuxième réponse est {np.mean(f1_second)}\")\n",
    "print(f\"La moyenne du f1 score de la deuxième réponse est {np.mean(f1_third)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S9-qNRPHBTE"
   },
   "source": [
    "**CamemBERT etalab** \n",
    "\n",
    "f1 moyen pour le meilleur dans les tops 3 réponses = **0.4410** \\\n",
    "La moyenne du f1 score de la première réponse est 0.30833837907250766 \\\n",
    "La moyenne du f1 score de la deuxième réponse est 0.15077226166061355 \\\n",
    "La moyenne du f1 score de la deuxième réponse est 0.08216946976350933 \\\n",
    "\n",
    "\n",
    "**CamemBERT etalab fine-tuné** \n",
    "\n",
    "f1 moyen pour le meilleur dans les tops 3 réponses = **0.4555** \\\n",
    "La moyenne du f1 score de la première réponse est 0.34376325079855674\\\n",
    "La moyenne du f1 score de la deuxième réponse est 0.14293577103049535\\\n",
    "La moyenne du f1 score de la deuxième réponse est 0.09896793972304943 \\\n",
    "\n",
    "**XLM-RoBERTa fine tune sur Texas-squad-fr** \n",
    "\n",
    "f1 moyen pour le meilleur dans les tops 3 réponses = **0.3785** \\\n",
    "La moyenne du f1 score de la première réponse est 0.24524329826585775 \\\n",
    "La moyenne du f1 score de la deuxième réponse est 0.15367713689846546 \\\n",
    "La moyenne du f1 score de la deuxième réponse est 0.04712201303167415\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej4TJezUplAl"
   },
   "outputs": [],
   "source": [
    "for data in data_test:\n",
    "  prediction = pipe.run(\n",
    "      query=\"\", \n",
    "      params={\"Reader\": {\"top_k\": 3}}\n",
    "  )\n",
    "\n",
    "# print the result \n",
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxH3z-0GdIYb"
   },
   "outputs": [],
   "source": [
    "for j in range(len(data_test[\"data\"])):\n",
    "    count=0\n",
    "    for i in range(len(dict_rapport)):\n",
    "    if dict_rapport[i][\"content\"]==data_test[\"data\"][j][\"paragraphs\"][0][\"context\"]:\n",
    "      #print(dict_rapport[i][\"content\"])\n",
    "      count+=1\n",
    "    if count==0:\n",
    "    # print(dict_rapport[i][\"content\"])\n",
    "    print(\"\\n\", data_test[\"data\"][j][\"paragraphs\"][0][\"context\"])\n",
    "#dict_rapport[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1648117595585,
     "user": {
      "displayName": "Louis Duverneuil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1mdxAvqwfThWq3nbAUw5ChQ8gCWYPpgNwjnHBSg=s64",
      "userId": "07615922061891370662"
     },
     "user_tz": -60
    },
    "id": "DueYjQMvdjzE",
    "outputId": "47cd37dd-7b24-43bb-b1f7-5f73c7f8ad1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Si les défis technologiques et de R&D associés apparaissent «dépassables» dans les décennies à venir, les scénarios «100% renouvelable» ou fondés sur la prolongation à long terme des réacteurs nucléaires actuels au-delà de 60 ans impliquent qu’un grand nombre de prérequis techniques critiques soient respectés à court terme. Or rien ne le garantit en l’état. Décider de ces scénarios aujourd’hui, ou renoncer au principe de diversification technologique dans le mix de production électrique, soulève donc un risque de non-atteinte de l’objectif de neutralité carbone à la date rapprochée de 2050.',\n",
       " 'document_id': 15,\n",
       " 'qas': [{'answers': [{'answer_category': 'SHORT',\n",
       "     'answer_id': 5015,\n",
       "     'answer_start': 247,\n",
       "     'document_id': 15,\n",
       "     'question_id': 1015,\n",
       "     'text': 'grand nombre de prérequis techniques critiques soient respectés à court terme'}],\n",
       "   'id': 1015,\n",
       "   'is_impossible': False,\n",
       "   'question': 'Que sous-entendent les scénarios 100% renouvelables ou de prolongation des centrales nucléaires au delà de 60 ans ?'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[\"data\"][0][\"paragraphs\"][0]# ['document_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IJe46YidHHA"
   },
   "outputs": [],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")\n",
    "report_path = \"/content/drive/MyDrive/Projet Option - ChatBot/0 - Biblio/rapport_rte_v2.json\"\n",
    "\n",
    "# Import text \n",
    "with open(report_path) as json_file:\n",
    "    dict_rapport = json.load(json_file)[\"data\"]\n",
    "\n",
    "# write document on ElasticSearch server\n",
    "document_store.write_documents(dict_rapport)\n",
    "\n",
    "## Initalize Retriever, Reader,  & Pipeline\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)\n",
    "reader = FARMReader(model_name_or_path=\"/content/drive/MyDrive/Projet Option - ChatBot/3 - Scripts/camembertV2\", use_gpu=True)\n",
    "# reader = FARMReader(model_name_or_path=\"saattrupdan/xlmr-base-texas-squad-fr\", use_gpu=True)\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Eval_metrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
